#!/usr/bin/env python3
#
# References:
# - https://github.com/virt-manager/virt-manager/blob/master/virtManager/viewers.py
# - http://lazka.github.io/pgi-docs/#SpiceClientGLib-2.0
# - spice-gtk/src/spicy-screenshot.c
# - https://linuxtv.org/downloads/v4l-dvb-apis/uapi/v4l/pixfmt-packed-rgb.html
# - http://zulko.github.io/blog/2013/09/27/read-and-write-video-frames-in-python-using-ffmpeg/
# - https://msdn.microsoft.com/en-us/library/windows/desktop/aa473780.aspx
# - https://superuser.com/a/1136854/101823
# - https://ffmpeg.org/ffmpeg-filters.html
# - https://ffmpeg.org/ffmpeg-filters.html#scale
# - https://ffmpeg.org/ffmpeg-filters.html#concat
import argparse
import logging
import time
import ctypes
from enum import Enum
import tempfile
import subprocess
import signal
import os

from gi.repository import GLib
from gi.repository import GObject

import gi
gi.require_version('SpiceClientGLib', '2.0')
from gi.repository import SpiceClientGLib

# Maximum framerate timer error allowance (percent of frame interval)
FRAMERATE_ERR_LIMIT_PCT = 10.0

class SpiceSurfaceFmt(Enum):
    # spice-1/spice/enums.h
    SPICE_SURFACE_FMT_INVALID = 0
    SPICE_SURFACE_FMT_1_A = 1
    SPICE_SURFACE_FMT_8_A = 8
    SPICE_SURFACE_FMT_16_555 = 16
    SPICE_SURFACE_FMT_32_xRGB = 32
    SPICE_SURFACE_FMT_16_565 = 80
    SPICE_SURFACE_FMT_32_ARGB = 96


class Display(GObject.GObject):
    def __init__(self, channel, width, height, stride, shmid, imgdata, outfile):
        self.channel = channel
        self.width   = width
        self.height  = height
        self.stride  = stride
        self.shmid   = shmid

        # Ensure there is no width padding
        # stride [bytes] == width [pixels] * 4 [bytes / pixel]
        assert(self.stride == self.width * self.bytes_per_pixel)

        imgdata_bytes = stride * height
        self.imgdata = ctypes.cast(imgdata, ctypes.POINTER(ctypes.c_ubyte * imgdata_bytes))

        self.outfile = outfile

        self._start_time = time.time()
        self._end_time = None
        self._num_frames_recorded = 0
        self._num_bytes_recorded = 0


    @staticmethod
    def get_format_class(format):
        return {
            SpiceSurfaceFmt.SPICE_SURFACE_FMT_32_xRGB:  Display32RGB,
            # TODO: Other formats
        }[format]

    def __repr__(self):
        return '{}(channel={}, width={}, height={}, stride={}, shmid={}, ' \
               'imgdata={}, outfile={})'.format(
                type(self), self.channel, self.width, self.height, self.stride,
                self.shmid, self.imgdata, self.outfile)


    def destroy(self):
        # Doesn't actually destroy anything -- called on destroy callback
        self.imgdata = None
        self._end_time = time.time()

    def write_frame(self):
        assert self.imgdata
        b = self._do_write_frame()
        self._num_frames_recorded += 1
        self._num_bytes_recorded += b
        return b

    @property
    def frames_recorded(self):
        return self._num_frames_recorded

    @property
    def bytes_recorded(self):
        return self._num_bytes_recorded

    @property
    def duration(self):
        end = self._end_time or time.time()
        return end - self._start_time


class Display32RGB(Display):
    bytes_per_pixel = 4
    ffmpeg_pix_fmt = 'bgr0'     # Each pixel is 4 bytes: BGR0,BGR0,...

    def _do_write_frame(self):
        return self.outfile.write(self.imgdata.contents)


class SpiceRecorder(GObject.GObject):
    __gsignals__ = {
        "periodic-update":  (GObject.SignalFlags.RUN_FIRST, None, []),
    }

    def __init__(self, framerate=24):
        GObject.GObject.__init__(self)

        self.framerate = framerate

        self._spice_session = None
        self._main_channel = None
        self._display_channel = None
        self._displays = []             # displays created, in chrono. order
        self._active_display = None     # currently active display

        self._last_frame_t = None

        self._last_periodic_update_t = None
        self._num_frames_recorded = 0
        self._num_bytes_recorded = 0
        self._start_time = None

    def _create_spice_session(self):
        self._spice_session = SpiceClientGLib.Session(read_only=True)
        SpiceClientGLib.set_session_option(self._spice_session)

        GObject.GObject.connect(self._spice_session, "channel-new",
                                self._channel_new_cb)

    def _channel_new_cb(self, session, channel):
        logging.debug("New channel signal: channel=%s", channel)

        # Dispatch
        cb = {
            SpiceClientGLib.MainChannel:    self._new_main_channel,
            SpiceClientGLib.DisplayChannel: self._new_display_channel
        }.get(type(channel))
        if cb:
            cb(channel)

    def _new_main_channel(self, channel):
            self._main_channel = channel
            self._main_channel.connect_after("channel-event",
                                        self._main_channel_event_cb)

    def _new_display_channel(self, channel):
            channel_id = channel.get_property("channel-id")
            if channel_id != 0:
                logging.warning("Spice multi-head unsupported")
                return

            if self._display_channel:
                logging.warning("Display channel already set")
                return
            self._display_channel = channel

            # See spice-gtk/src/spice-widget.c:channel_new()
            self._display_channel.connect_after("display-primary-create",
                                           self._display_primary_create_cb)
            self._display_channel.connect_after("display-primary-destroy",
                                           self._display_primary_destroy_cb)

            channel.connect()



    def _main_channel_event_cb(self, channel, event):
        logging.debug("Main channel %s event %s", channel, event)

    def _display_primary_create_cb(self, channel, format, width, height, stride, shmid, imgdata):
        format = SpiceSurfaceFmt(format)
        logging.debug("display-primary-create channel=%s format=%s %dx%d", channel, format, width, height)
        if self._active_display:
            logging.warning("Hmm? _active_display is set: %s", self._active_display)
            return

        rawf = tempfile.NamedTemporaryFile('w+b', prefix='spice-record-',
                suffix='{}x{}.raw'.format(width, height), delete=False)
        d = Display.get_format_class(format)(channel, width, height, stride, shmid, imgdata, rawf)
        logging.debug("New display: %s", d)
        self._active_display = d
        self._displays.append(d)

        # First display?
        if len(self._displays) == 1:
            self._start_time = time.time()
            self._record_frame()
            GLib.timeout_add(int(1000 / self.framerate), self._record_frame)

    def _display_primary_destroy_cb(self, channel):
        logging.debug("display-primary-destroy channel %s", channel)

        self._active_display.destroy()
        self._active_display = None

    def _record_frame(self):
        now = time.time()

        # Calculate framerate timer error
        t_frame = 1 / self.framerate
        if self._last_frame_t:
            dt = now - self._last_frame_t
            err = dt - t_frame
            err_pct = (err / t_frame) * 100
            if err_pct > FRAMERATE_ERR_LIMIT_PCT:
                logging.warning("Framerate error exceeds threshold: dt={} err={} ({}%)".format(dt, err, err_pct))
        self._last_frame_t = now

        # Ugh, can we miss frames here while there is no display?
        if not self._active_display:
            return

        # Write the frame!
        b = self._active_display.write_frame()
        self._num_frames_recorded += 1
        self._num_bytes_recorded += b

        # Perform periodic update
        if self._last_periodic_update_t:
            dt = now - self._last_periodic_update_t
        if not self._last_periodic_update_t or (dt > 1.0):
            self.emit("periodic-update")
            self._last_periodic_update_t = now

        return True

    @property
    def displays(self):
        return list(self._displays)

    @property
    def elapsed_time(self):
        return time.time() - self._start_time

    @property
    def frames_recorded(self):
        return self._num_frames_recorded

    @property
    def bytes_recorded(self):
        return self._num_bytes_recorded

    def get_resolution(self):
        if not self._display_channel:
            return None
        return self._display_channel.get_properties("width", "height")

    def open_host(self, host='localhost', port=5900, tlsport=None):
        self._create_spice_session()

        logging.debug("Spice connecting to host=%s port=%s tlsport=%s",
            host, port, tlsport)
        self._spice_session.set_property("host", str(host))
        if port:
            self._spice_session.set_property("port", str(port))
        if tlsport:
            self._spice_session.set_property("tls-port", str(tlsport))

        self._spice_session.connect()


def convert_concat_videos(displays, framerate, outcodec, outpath, loglevel=None):
    ffmpeg_args = [
        'ffmpeg',
        '-loglevel', loglevel,
        '-y',
    ]

    # Determine the output video resolution
    maxw, maxh = 0, 0
    for d in displays:
        maxw = max(maxw, d.width)
        maxh = max(maxh, d.height)

    # Establish raw input files with their attributes
    for d in displays:
        ffmpeg_args += [
            '-f', 'rawvideo',
            '-vcodec', 'rawvideo',
            '-pix_fmt', d.ffmpeg_pix_fmt,
            '-r', str(framerate),
            '-an',
            '-s', '{}x{}'.format(d.width, d.height),
            '-i', d.outfile.name,   # TODO: "pipe:{fd}"
        ]

    # Build our complex filtergraph:
    # 1) Create appropriately scaled versions of each input stream named [v{i}]
    filters = []
    for i,d in enumerate(displays):
        # Explained:
        #   [{i}:v]     Take the i'th input file's video stream,
        #   scale=      Scale it to w x h, maintaining aspect ratio,
        #               decreasing the output size if required to do so,
        #   pad=        And if so, pad it out to w x h, centering it in the frame.
        #   [v{i}]      Name the output stream [v{i}]
        filt = '[{i}:v] scale={w}:{h}:force_original_aspect_ratio=decrease,' \
                'pad={w}:{h}:(ow-iw)/2:(oh-ih)/2  [v{i}]'.format(
                i=i, w=maxw, h=maxh)
        filters.append(filt)

    # 2) Concatenate the [v{i}] videos to [outv]
    # Explained:
    #   [v{i}]      Take each of the [v{i}] scaled streams,
    #   concat=     concatenate all 'n' of them together into one video output.
    #   [outv]      Name the output stream [outv]
    filt = ' '.join('[v{i}]'.format(i=i) for i in range(len(displays)))
    filt += 'concat=n={n}:v=1:a=0 [outv]'.format(n=len(displays))
    filters.append(filt)


    ffmpeg_args += [
        # Apply the compex filtergraph
        '-filter_complex', '; '.join(filters),

        # Specify output video parameters
        '-vcodec', outcodec,
        '-pix_fmt', 'yuv420p',  # avoid warning

        # Map the [outv] to the output file
        '-map', '[outv]',
        outpath
    ]
    logging.debug("Invoking FFMPEG: {}".format(ffmpeg_args))
    subprocess.check_call(ffmpeg_args)



def logging_to_ffmpeg_loglevel(ll):
    return {
        'DEBUG':    'debug',
        'INFO':     'info',
        'WARNING':  'warning',
        'ERROR':    'error',
        'CRITICAL': 'fatal',
    }[ll]

def parse_args():
    ap = argparse.ArgumentParser()
    ap.add_argument('output')
    ap.add_argument('--vcodec', default='libx264',
            help='Set the output video codec (see "ffmpeg -encoders" for choices)')
    ap.add_argument('--loglevel', choices=['DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'],
            help='Set the logging level', default='WARNING')
    ap.add_argument('-r', '--framerate', type=int, default=24)
    return ap.parse_args()

def format_datasize(b):
    suffixes = ['', 'ki', 'Mi', 'Gi', 'Ti']
    for s in suffixes:
        if (b < 1024) or (s == suffixes[-1]):
            break
        b /= 1024.0
    return '{:0.02f} {}B'.format(b, s)

def main():
    args = parse_args()
    logging.basicConfig(level=args.loglevel)


    # Record raw video
    sp = SpiceRecorder(framerate=args.framerate)
    sp.open_host()

    def periodic_update(sp):
        print("\r" + " "*80, end="")
        print("\r{:<20}{:<20}{:<20}".format(
            "{:0.02f} sec".format(sp.elapsed_time),
            "{} frames".format(sp.frames_recorded),
            format_datasize(sp.bytes_recorded),
            ), end="")
    sp.connect("periodic-update", periodic_update)

    loop = GLib.MainLoop()

    def sigint_handler(signum, frame):
        print("INTERRUPT")
        loop.quit()
    old = signal.signal(signal.SIGINT, sigint_handler)

    print("Recording... Press Ctrl+C to stop")
    loop.run()
    signal.signal(signal.SIGINT, old)

    print("-"*80)
    print("Recorded displays:")
    maxw, maxh = 0, 0
    for n,d in enumerate(sp.displays):
        print("  {}: {}x{} {:>4} frames  {:>10}  {:0.02f} sec".format(n, d.width, d.height,
            d.frames_recorded,
            format_datasize(d.bytes_recorded),
            d.duration))
        maxw = max(maxw, d.width)
        maxh = max(maxh, d.height)
    print("Final: {}x{}".format(maxw, maxh))
    print("-"*80)


    # Convert video
    print("\nDone recording. Converting...")
    convert_concat_videos(
            displays = sp.displays,
            framerate = args.framerate,
            outcodec = args.vcodec,
            outpath = args.output,
            loglevel = logging_to_ffmpeg_loglevel(args.loglevel),
            )

    # TODO: Pass tempfile file descriptors to ffmpeg using -i pipe:{fd}.
    # This requires passing close_fds=False.
    # Note that we can't currently do this because the tempfiles were opened
    # in a different process (thanks to MainLoop)!


if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        print("Exiting due to Ctrl+C")
